# -*- coding: utf-8 -*-
"""chenni house prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xYAHdxkoPUU0eWX8sQSWGLxgXjT1rmvt
"""

!pip install matplotlib

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/train-chennai-sale.csv'

data = pd.read_csv('/content/drive/MyDrive/train-chennai-sale.csv')

data.shape

data.head()

"""**Droping the unwanted columns**"""

data = data.drop(columns = ['PRT_ID'])

data.head()

"""**Finding the datatypes of the columns**"""

data.dtypes

"""**AREA**

"""

data.AREA.values

data.AREA.unique()

data.AREA.replace('Karapakam','Karapakkam', inplace=True)
data.AREA.replace('karapakkam','Karapakkam', inplace=True)
data.AREA.replace('Adyr','Adyar', inplace=True)
data.AREA.replace('KKNagar','KK Nagar', inplace=True)
data.AREA.replace('TNagar','T Nagar', inplace=True)
data.AREA.replace('Ann Nagar','Anna Nagar', inplace=True)
data.AREA.replace('Ana Nagar','Anna Nagar', inplace=True)
data.AREA.replace('Chrompt','Chrompet', inplace=True)
data.AREA.replace('Chormpet','Chrompet', inplace=True)
data.AREA.replace('Chrmpet','Chrompet', inplace=True)
data.AREA.replace('Velchery','Velachery', inplace=True)

data.AREA.unique()

data.AREA.isnull().sum()

"""**INT_SQFT** 

"""

data.INT_SQFT.describe()

"""Here minimum sqft is 500
maximum sqft is 7100
"""

data.INT_SQFT.isnull().sum()

data.DATE_SALE.isnull().sum()

"""**TO CALCULATE THE AGE OF THE BUILDING**"""

data.DATE_BUILD = pd.to_datetime(data.DATE_BUILD)
data.DATE_SALE = pd.to_datetime(data.DATE_SALE)

data.DATE_BUILD = data.DATE_BUILD.dt.year
data.DATE_SALE = data.DATE_SALE.dt.year

data["B_AGE"] = data.DATE_SALE - data.DATE_BUILD

data.head()

data = data.drop(columns=['DATE_BUILD','DATE_SALE'])

data.head()

data.columns

"""**DISTANCE FROM MAINROAD**"""

data.DIST_MAINROAD.describe()

data.DIST_MAINROAD.isnull().sum()

"""**NO OF BEDROOMS**"""

data.N_BEDROOM.describe()

data.N_BEDROOM.isnull().sum()

data = data.fillna(data['N_BEDROOM'].mode()[0])

data.N_BEDROOM.isnull().sum()

data.N_BEDROOM.describe()

"""**NO OF ROOMS**"""

data.N_ROOM.isnull().sum()

"""**NO OF BATHROOM**"""

data.N_BATHROOM.describe()

data.N_BATHROOM.isnull().sum()

"""**SALE_COND**"""

data.SALE_COND.isnull().sum()

data.SALE_COND.unique()

data.SALE_COND.replace('Ab Normal','Abnormal',inplace = True)
data.SALE_COND.replace('AbNormal','Abnormal',inplace = True)
data.SALE_COND.replace('Adj Land','AdjLand',inplace = True)
data.SALE_COND.replace('Partiall','Partial',inplace = True)
data.SALE_COND.replace('PartiaLl','Partial',inplace = True)

data.SALE_COND.unique()

"""**PARK_FACIL**"""

data.PARK_FACIL.isnull().sum()

data.PARK_FACIL.unique()

data.PARK_FACIL.replace('Noo','No',inplace = True)

data.PARK_FACIL.unique()

"""**BUILDTYPE**"""

data.BUILDTYPE.isnull().sum()

data.BUILDTYPE.unique()

data.BUILDTYPE.replace('Other','Others',inplace = True)
data.BUILDTYPE.replace('Comercial','Commercial',inplace = True)

data.BUILDTYPE.unique()

"""**STREET**"""

data.STREET.isnull().sum()

data.STREET.unique()

data.STREET.replace('Pavd','Paved',inplace = True)
data.STREET.replace('NoAccess','No Access',inplace = True)

data.STREET.unique()

"""**UTILITY_AVAIL**"""

data.UTILITY_AVAIL.isnull().sum()

data.UTILITY_AVAIL.unique()

data.UTILITY_AVAIL.replace('AllPub','All Pub',inplace = True)

data.UTILITY_AVAIL.unique()

"""**QS_OVERALL**"""

data.QS_OVERALL.isnull().sum()

data = data.fillna(data['QS_OVERALL'].mean())

data.QS_OVERALL.isnull().sum()

"""**SALES_PRICE**"""

data.SALES_PRICE.isnull().sum()

data.SALES_PRICE.describe()

data = data.drop(columns=['REG_FEE','COMMIS'])

data.head()

"""**VIZUALIZATION OF DATA**"""

#A=data.AREA.groupby(data.AREA).count()
#A=data.AREA.groupby(data.AREA).count()
#A=data.AREA.groupby(data.AREA).count()
#A=data.AREA.groupby(data.AREA).count()
#A=data.AREA.groupby(data.AREA).count()
#A=data.AREA.groupby(data.AREA).count()

sns.set_theme(style="darkgrid", palette="pastel")
plt.figure(figsize=(20,16))
plt.subplot(231)
sns.barplot(x=data.AREA.index,y=data.AREA.values,data = data)
plt.xticks(rotation=20)
plt.title('NO OF HOUSES(AREA)')
plt.show()

sns.set_theme(style="darkgrid", palette="pastel")
plt.figure(figsize=(10,10))
plt.subplot(232)
sns.barplot(x=data.PARK_FACIL.index,y=data.PARK_FACIL.values,data = data)
plt.xticks(rotation=20)
plt.title('TOTAL HOUSES(PARKING FACILITY)')

#plt.subplot(233)
#sns.barplot(x=data.BUILDTYPE.index,y=data.BUILDTYPE.values,data = data)
#plt.xticks(rotation=15)
plt.title('TOTAL HOUSES(BUILDING TYPE)')
sns.barplot(x=data.BUILDTYPE.index,y=data.BUILDTYPE.values,data = data)
plt.show()

plt.subplot(233)
sns.barplot(x=data.UTILITY_AVAIL.index,y=data.UTILITY_AVAIL.values,data = data)
plt.xticks(rotation=15)
plt.title('TOTAL HOUSES(UTILITY AVAILABLE)')

plt.subplot(234)
sns.barplot(x=data.STREET.index,y=data.STREET.values,data = data)
plt.xticks(rotation=20)
plt.title('TOTAL HOUSES(NATURE OF STREET)')

plt.subplot(235)
sns.barplot(x=data.MZZONE.index,y=data.MZZONE.values,data = data)
plt.xticks(rotation=15)
plt.title('TOTAL HOUSES(NATURE OF ZONE)')

"""**FEATURE VS TARGET**

---


"""

plt.figure(figsize=(27,10))
plt.subplot(231)
sns.barplot(x=data.AREA,y=data.SALES_PRICE,order=data.groupby('AREA')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['AREA'])
plt.title("TO FIND AREA VS SALESPRICE")

plt.figure(figsize=(10,10))
plt.subplot(231)
sns.barplot(x=data.PARK_FACIL,y=data.SALES_PRICE,order=data.groupby('PARK_FACIL')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['PARK_FACIL'])
plt.title("TO FIND PARKING FACILITY VS SALESPRICE")

plt.figure(figsize=(15,10))
plt.subplot(231)
sns.barplot(x=data.UTILITY_AVAIL,y=data.SALES_PRICE,order=data.groupby('UTILITY_AVAIL')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['UTILITY_AVAIL'])
plt.title("TO FIND UTILITY_AVAILABLE VS SALESPRICE")

plt.figure(figsize=(10,10))
plt.subplot(231)
sns.barplot(x=data.STREET,y=data.SALES_PRICE,order=data.groupby('STREET')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['STREET'])
plt.title("TO FIND AREA VS SALESPRICE")

plt.figure(figsize=(15,10))
plt.subplot(231)
sns.barplot(x=data.MZZONE,y=data.SALES_PRICE,order=data.groupby('MZZONE')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['MZZONE'])
plt.title("TO FIND MZZONE VS SALESPRICE")

plt.figure(figsize=(10,10))
plt.subplot(231)
sns.barplot(x=data.BUILDTYPE,y=data.SALES_PRICE,order=data.groupby('BUILDTYPE')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['BUILDTYPE'])
plt.title("TO FIND TYPE OF BUILDING VS SALESPRICE")

data.head()

"""**Numerical and Continuous Data Split**"""

Numerical_features=[feature for feature in data.columns if data[feature].dtypes !='O']
Numerical_features

Continuous_features=[feature for feature in data.columns if data[feature].dtypes == 'O']
Continuous_features

"""**EDA OF NUMERICAL DATA**"""

target = data.SALES_PRICE

plt.figure(figsize=(5,5))
sns.regplot(x=data.INT_SQFT,y=target,color ='r')
plt.title('INT_SQFT VS SALES_PRICE')

"""**There is a linear relationship between sales price and int_sqft.So INT_SQFT increases sales price increases**







"""

plt.figure(figsize=(5,5))
sns.regplot(x=data.DIST_MAINROAD,y=target,color ='b')
plt.title('DIST_MAINROAD VS SALES_PRICE')

"""**There is no linear relationship between sales price and DIST_MAINROAD.**

"""

plt.figure(figsize=(5,5))
sns.regplot(x=data.N_BEDROOM,y=target,color ='r')
plt.title('N_BEDROOM VS SALES_PRICE')

"""**There is a linear relationship between sales price and N_BEDROOM.So if N_BEDROOM increases sales price also increases**

"""

plt.figure(figsize=(5,5))
sns.regplot(x=data.N_BATHROOM,y=target,color ='B')
plt.title('N_BATHROOM VS SALES_PRICE')

"""**There is a linear relationship between sales price and N_BATHROOM.So if N_BATHROOM increases sales price increases**

"""

plt.figure(figsize=(5,5))
sns.regplot(x=data.N_ROOM,y=target,color ='G')
plt.title('N_ROOM VS SALES_PRICE')

"""**There is a linear relationship between sales price and N_ROOM.So if N_ROOM increases sales price also increases**

"""

plt.figure(figsize=(5,5))
sns.regplot(x=data.QS_ROOMS,y=target,color ='r')
plt.title('QS_ROOMS VS SALES_PRICE')

"""**There is no linear relationship between sales price and QS_ROOMS.**"""

plt.figure(figsize=(5,5))
sns.regplot(x=data.QS_BATHROOM,y=target,color ='B')
plt.title('QS_BATHROOM VS SALES_PRICE')

"""**There is a no linear relationship between sales price and QS_BATHROOM.**"""

plt.figure(figsize=(5,5))
sns.regplot(x=data.QS_BEDROOM,y=target,color ='G')
plt.title('QS_BEDROOM VS SALES_PRICE')

"""**There is no linear relationship between sales price and QS_BEDROOM.**"""

plt.figure(figsize=(10,10))
sns.regplot(x=data.B_AGE,y=target,color ='r')
plt.title('B_AGE VS SALES_PRICE')

"""**There is a linear relationship between sales price and B_AGE.So if B_AGE increases sales price decreases**

**EDA OF CATEGORICAL DATA**
"""

plt.figure(figsize=(27,10))
plt.subplot(231)
sns.barplot(x=data.AREA,y=data.SALES_PRICE,order=data.groupby('AREA')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['AREA'])
plt.title("TO FIND AREA VS SALESPRICE")

plt.figure(figsize=(25,10))
plt.subplot(232)
sns.barplot(x=data.SALE_COND,y=data.SALES_PRICE,order=data.groupby('SALE_COND')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['SALE_COND'])
plt.title("TO FIND SALE CONDITION VS SALESPRICE")

plt.figure(figsize=(10,10))
plt.subplot(233)
sns.barplot(x=data.PARK_FACIL,y=data.SALES_PRICE,order=data.groupby('PARK_FACIL')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['PARK_FACIL'])
plt.title("TO FIND PARKING FACILITY VS SALESPRICE")

plt.figure(figsize=(10,10))
plt.subplot(234)
sns.barplot(x=data.BUILDTYPE,y=data.SALES_PRICE,order=data.groupby('BUILDTYPE')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['BUILDTYPE'])
plt.title("TO FIND BUILDING TYPE VS SALESPRICE")

plt.figure(figsize=(15,10))
plt.subplot(235)
sns.barplot(x=data.UTILITY_AVAIL,y=data.SALES_PRICE,order=data.groupby('UTILITY_AVAIL')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['UTILITY_AVAIL'])
plt.title("TO FIND UTILITY_AVAILABLE VS SALESPRICE")

plt.figure(figsize=(10,10))
plt.subplot(236)
sns.barplot(x=data.STREET,y=data.SALES_PRICE,order=data.groupby('STREET')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['STREET'])
plt.title("TO FIND STREET VS SALESPRICE")

plt.figure(figsize=(20,10))
plt.subplot(236)
sns.barplot(x=data.MZZONE,y=data.SALES_PRICE,order=data.groupby('MZZONE')['SALES_PRICE'].mean().reset_index().sort_values('SALES_PRICE')['MZZONE'])
plt.title("TO FIND MZZONE VS SALESPRICE")

"""**ENCODING**

AREA shows a linear relationship hence linear encoding is done
"""

data.AREA= data.AREA.map({'Karapakkam':1,'Adyar':2,'Chrompet':3,'Velachery':4,'KK Nagar':5,'Anna Nagar':6,'T Nagar':7})

"""SALE_COND shows a linear relationship hence label encoding is done"""

data.SALE_COND=data.SALE_COND.map({'Partial':1,'Family':2,'Abnormal':3,'Normal Sale':4,'AdjLand':5})

"""PARK_FACIL shows a linear relationship hence label encoding is done """

data.PARK_FACIL=data.PARK_FACIL.map({'No':1,'Yes':2})

"""BUILDTYPE shows a slight linear relationship hence label encoding is done

> Indented block


"""

#data.BUILDTYPE=data.BUILDTYPE.map({'House':1,'Others':2,'Commercial':4})

"""UTILITY_AVAILABLE shows a linear relationship hence label encoding is done"""

data.UTILITY_AVAIL=data.UTILITY_AVAIL.map({'ELO':1,'NoSeWa':2,'NoSewr ':3,'All Pub':4})

"""STREET shows a linear relationship hence label encoding is done """

data.STREET=data.STREET.map({'No Access':1,'Paved':2,'Gravel':3})

"""MZZONE shows a linear relationship hence label encoding is done """

data.MZZONE=data.MZZONE.map({'A':1,'C':2,'I':3,'RH':5,'RL':6,'RM':7})

"""BUILDTYPE has no linear relationship hence onehot encoding is done"""

onehot = pd.get_dummies(data.BUILDTYPE).astype(int)
data = data.join(onehot)

data.columns

data.head()

data=data.drop(columns= ['BUILDTYPE','QS_ROOMS','QS_BATHROOM','QS_BEDROOM','QS_OVERALL'])

data.columns

data.head()

data.info()

data.N_BATHROOM = data.N_BATHROOM.astype(int)
data.N_BEDROOM = data.N_BEDROOM.astype(int)

"""**LINEAR REGRESSION**"""

X = data[['AREA','INT_SQFT','DIST_MAINROAD','N_BEDROOM','N_BATHROOM','N_ROOM','SALE_COND','PARK_FACIL',
          'UTILITY_AVAIL','STREET','MZZONE','B_AGE','Commercial','House','Others']]
Y = data['SALES_PRICE']

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler

from sklearn.linear_model import LinearRegression

from sklearn import metrics

"""**TRAIN_TEST**"""

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)

X_train.shape,X_test.shape

regressor = LinearRegression()
regressor.fit(X_train,Y_train)

Y_pred = regressor.predict(X_test)
Y_pred

df = pd.DataFrame({'Actual':Y_test,'Predicted':Y_pred})
df

print('R2 score:',metrics.r2_score(Y_test,Y_pred))

"""**CONCLUSION ON LINEAR REGRESSION** 

---


 We have built a linear regression model and found R2 score of 0.92.

---



---



---

**DECISION TREE ALGORITHM**
"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor

from sklearn.metrics import mean_squared_error, r2_score

X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.2,random_state=1)

dt = DecisionTreeRegressor()
dt.fit(X_train,Y_train)
dt.predict(X_test),Y_test

Y_pred = dt.predict(X_test)
MSE_dt= mean_squared_error(Y_test,Y_pred)
rsquared = r2_score(Y_test,Y_pred)
RSME_dt = MSE_dt ** (1/2)
print('test set RSME of dt:{:.2f}'.format(RSME_dt))
print('test set r2 of dt:{:.2f}'.format(rsquared))

"""**CONCLUSION ON DECISION TREE ALGORITHM**


---

We have built decision tree model and found r2 score of 0.97.
the observation is our model is giving results based on 97% of data.
Decision tree is a good validation model for price of house prediction in Chennai City.

The main key features here are **AREA,N_ROOMS,N_BEDROOMS,N_BATHROOMS,B_AGE**
 .Here our training model can explain **97% of data**.

**KNN ALGORITHM**

---
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import cross_val_score
from sklearn import neighbors
from sklearn.metrics import mean_squared_error 
from math import sqrt
# %matplotlib inline

X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.2)

X_train.shape,X_test.shape

rmse_val = []
for K in range(30):
  K=K+1
  dt = neighbors.KNeighborsRegressor(n_neighbors = K)
  dt.fit(X_train, Y_train)
  pred=dt.predict(X_test) 
  error = sqrt(mean_squared_error(Y_test,pred)) 
  rmse_val.append(error) 
  print('RMSE value for k= ' , K , 'is:', error)

#plotting the rmse values against k values
curve = pd.DataFrame(rmse_val) #elbow curve 
curve.plot()

from sklearn.model_selection import GridSearchCV
params = {'n_neighbors':[2,3,4,5,6,7,8,9,10,20,30,40,50]}

knn = neighbors.KNeighborsRegressor()

dt = GridSearchCV(knn, params, cv=5)
dt.fit(X_train,Y_train)
dt.best_params_